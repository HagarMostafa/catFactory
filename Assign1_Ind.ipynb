{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba442ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20829a66",
   "metadata": {},
   "source": [
    "## Data Initialsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a84a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (distance)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# outputs (velocity)\n",
    "vx = []\n",
    "vy = []\n",
    "\n",
    "# parse the data into the set container\n",
    "with open('ce889_dataCollectionN.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    for line in csv_reader:\n",
    "        x.append(float(line[0]))\n",
    "        y.append(float(line[1]))\n",
    "        vx.append(float(line[2]))\n",
    "        vy.append(float(line[3]))\n",
    "\n",
    "inputs = list(zip(x,y))\n",
    "outputs = list(zip(vx,vy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68766712",
   "metadata": {},
   "source": [
    "## Neuron Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a493d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "        \n",
    "    def sigmoid(self,inputs):\n",
    "        sig = 1 / (1+math.exp(-inputs))\n",
    "        return sig\n",
    "    \n",
    "    def activate(self, prev_layer, index):\n",
    "        total = 0\n",
    "        for i in range(0, len(prev_layer)):\n",
    "            total = total + float(prev_layer[i].activationValue) * prev_layer[i].weights[index]\n",
    "            self.activationValue = self.sigmoid(total)\n",
    "#     def updateWeight\n",
    "            \n",
    "    def __init__ (self, activationValue, numberOfweights, layerIndex):\n",
    "        self.activationValue = activationValue\n",
    "        self.weights= [random() for i in range(numberOfweights + 1)]\n",
    "        self.delta_weight = [0,0]\n",
    "        self.grad_val = 0\n",
    "        self.layerIndex = layerIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cad270d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9484779356072921, 0.44594262981200095, 0.7258933336870566, 0.5915352477197416, 0.5681593154901389, 0.25628357870218976]\n"
     ]
    }
   ],
   "source": [
    "# Debugging ( just a cat passing by üêà)\n",
    "randCat = [random() for i in range(5+1)]\n",
    "print (randCat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b9d9d",
   "metadata": {},
   "source": [
    "## Network Initialsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b627a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialsation of the network\n",
    "bias = -0.5\n",
    "n_hiddenNeurons = 3\n",
    "n_outNeurons = 2\n",
    "\n",
    "# Network\n",
    "# network = [neuron(0,n_hiddenNeurons,0),\n",
    "#            neuron(0,n_hiddenNeurons,0),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,0,2),\n",
    "#            neuron(0,0,2)\n",
    "#           ]\n",
    "\n",
    "input_layer = [neuron(0,n_hiddenNeurons,0),\n",
    "               neuron(0,n_hiddenNeurons,0)]\n",
    "\n",
    "hidden_layer = [neuron(0,n_outNeurons,1),\n",
    "                neuron(0,n_outNeurons,1),\n",
    "                neuron(0,n_outNeurons,1)]\n",
    "\n",
    "output_layer = [neuron(0,0,2),\n",
    "                neuron(0,0,2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ece0abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual weight adjustment\n",
    "\n",
    "# input_layer[0].weights = [0.1,0.1,0.1,bias]\n",
    "# input_layer[1].weights = [0.1,0.1,0.1,bias]\n",
    "\n",
    "# Add Bias to the end of the weight list\n",
    "# hidden_layer[0].weights = [0.7,0.7,bias]\n",
    "# hidden_layer[1].weights = [0.5,0.5,bias]\n",
    "# hidden_layer[2].weights = [0.6,0.6,bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85b2d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.686055895514416, 0.6707281446897904]\n",
      "1 [0.686055895514416, 0.6707281446897904]\n",
      "2 [0.686055197741248, 0.6707134121567286]\n",
      "3 [0.6860752195585151, 0.6707261150991785]\n",
      "4 [0.6860945398785202, 0.6707240852255013]\n",
      "5 [0.6861345699320133, 0.6707494874979106]\n",
      "6 [0.6861738886557904, 0.6707601558609563]\n",
      "7 [0.6862338979606769, 0.6707982479093478]\n",
      "8 [0.6862931801190313, 0.6708216042778041]\n",
      "9 [0.6863731241785819, 0.6708723705650323]\n",
      "10 [0.6864523191486784, 0.6709083986212131]\n",
      "11 [0.6865521379282529, 0.6709718176471492]\n",
      "12 [0.6866511795421727, 0.6710204952514414]\n",
      "13 [0.6867707970672067, 0.6710965393434672]\n",
      "14 [0.6868896030170394, 0.6711578379832263]\n",
      "15 [0.6870289272865885, 0.6712464732954182]\n",
      "16 [0.6871673991003877, 0.6713203582439734]\n",
      "17 [0.6873263215843711, 0.6714215444988849]\n",
      "18 [0.687484344233029, 0.6715079747461835]\n",
      "19 [0.6876627396444269, 0.671621665157269]\n",
      "20 [0.6878401809885686, 0.6717205929048106]\n",
      "21 [0.688039749057069, 0.6718503870608227]\n",
      "22 [0.688241953804264, 0.6719726894051229]\n",
      "23 [0.6884697697646961, 0.6721330200038199]\n",
      "24 [0.6887036646460932, 0.6722929935131013]\n",
      "25 [0.688945318166837, 0.6724561419731229]\n",
      "26 [0.6891963665725308, 0.6726259494609012]\n",
      "27 [0.6894584004855027, 0.6728058473982996]\n",
      "28 [0.6897329623654361, 0.6729992091545052]\n",
      "29 [0.6900215436352723, 0.6732093439834123]\n",
      "30 [0.6903255823582003, 0.6734394912061195]\n",
      "31 [0.6906464601808687, 0.673692813597414]\n",
      "32 [0.6909854997933673, 0.6739723907100537]\n",
      "33 [0.6913439620285334, 0.6742812118406882]\n",
      "34 [0.6917230430081385, 0.6746221686062078]\n",
      "35 [0.6921238713520736, 0.6749980474058345]\n",
      "36 [0.692547505042332, 0.6754115214354653]\n",
      "37 [0.6929949288317069, 0.6758651427199537]\n",
      "38 [0.6934670509258599, 0.6763613334245722]\n",
      "39 [0.6939647001964788, 0.6769023774079077]\n",
      "40 [0.6944886231792379, 0.6774904114326303]\n",
      "41 [0.6950394810172861, 0.6781274158937441]\n",
      "42 [0.6956178462456919, 0.6788152054540467]\n",
      "43 [0.696224199903029, 0.6795554198101278]\n",
      "44 [0.6968589285339045, 0.6803495141551573]\n",
      "45 [0.6975223207863265, 0.6811987491171622]\n",
      "46 [0.698214564747055, 0.6821041816054421]\n",
      "47 [0.6989357446379436, 0.6830666547287944]\n",
      "48 [0.699685838079656, 0.6840867886412371]\n",
      "49 [0.7004647131787505, 0.6851649711669325]\n",
      "50 [0.7012717778069474, 0.686299936134068]\n",
      "51 [0.7020553132845639, 0.687402005221467]\n",
      "52 [0.7028155952732256, 0.6884715854386059]\n",
      "53 [0.7035529006514498, 0.6895090910704856]\n",
      "54 [0.704267506337983, 0.6905149414667344]\n",
      "55 [0.7049596888372933, 0.6914895597207248]\n",
      "56 [0.7056297230435145, 0.6924333705514395]\n",
      "57 [0.7062778820190317, 0.6933467993595525]\n",
      "58 [0.7069044360567267, 0.6942302705325406]\n",
      "59 [0.7075096522524774, 0.6950842062816809]\n",
      "60 [0.7080937939160323, 0.6959090255467463]\n",
      "61 [0.7086571200341824, 0.6967051427988559]\n",
      "62 [0.7091998848334885, 0.6974729671025471]\n",
      "63 [0.7097223372924221, 0.6982129011393834]\n",
      "64 [0.7102247209413292, 0.6989253405959422]\n",
      "65 [0.7107072733157891, 0.6996106731927807]\n",
      "66 [0.7111702256565294, 0.7002692780466135]\n",
      "67 [0.7116138027041701, 0.700901525070631]\n",
      "68 [0.7120382223860456, 0.7015077744794559]\n",
      "69 [0.712443695538576, 0.7020883761620051]\n",
      "70 [0.7128304256490721, 0.702643669200386]\n",
      "71 [0.7131986089010468, 0.7031739817324532]\n",
      "72 [0.7135484335288225, 0.7036796300776064]\n",
      "73 [0.7138800802105802, 0.7041609189323309]\n",
      "74 [0.7141937215102987, 0.7046181408243457]\n",
      "75 [0.7144895219459713, 0.7050515757823667]\n",
      "76 [0.7147676377018523, 0.7054614912201376]\n",
      "77 [0.71502821684153, 0.7058481417956849]\n",
      "78 [0.7152713988097811, 0.7062117689877471]\n",
      "79 [0.7154973147396358, 0.7065526012931045]\n",
      "80 [0.7157060870737042, 0.7068708536884484]\n",
      "81 [0.7158978296758947, 0.7071667277992882]\n",
      "82 [0.7160726477395194, 0.7074404117723734]\n",
      "83 [0.7162306377132516, 0.7076920799859925]\n",
      "84 [0.7163718873079647, 0.7079218932150464]\n",
      "85 [0.7164964753699761, 0.7081299983878953]\n",
      "86 [0.7166044719588488, 0.7083165285936881]\n",
      "87 [0.716695938278029, 0.7084816030992714]\n",
      "88 [0.7167709266202134, 0.7086253271975912]\n",
      "89 [0.7168294803332548, 0.7087477921943127]\n",
      "90 [0.7168716339256318, 0.7088490754194875]\n",
      "91 [0.7168974128647653, 0.7089292401827202]\n",
      "92 [0.716906833715348, 0.7089883357495098]\n",
      "93 [0.7168999041515801, 0.7090263973667296]\n",
      "94 [0.7168766227091052, 0.7090434460771136]\n",
      "95 [0.7168369790998349, 0.7090394889865833]\n",
      "96 [0.7167809539592945, 0.7090145190192447]\n",
      "97 [0.7167085190119334, 0.7089685150399346]\n",
      "98 [0.7166365603695535, 0.7089342341961397]\n",
      "99 [0.7165481378529184, 0.7088788849171519]\n",
      "100 [0.7164601537422313, 0.7088352532799809]\n",
      "101 [0.7163556400931075, 0.7087705111580481]\n",
      "102 [0.7162515195231105, 0.7087174799782915]\n",
      "103 [0.7161307920301967, 0.7086432884903118]\n",
      "104 [0.7160104050693683, 0.7085808003257679]\n",
      "105 [0.7159178812122726, 0.7085718664651081]\n",
      "106 [0.7158532650049908, 0.7086165146506725]\n",
      "107 [0.7158165658993473, 0.7087146880569334]\n",
      "108 [0.7158077578246737, 0.7088662447064237]\n",
      "109 [0.7158267791557356, 0.7090709573254624]\n",
      "110 [0.7158738145794326, 0.7093297045011209]\n",
      "111 [0.715948952024193, 0.7096431723082468]\n",
      "112 [0.7160521803044543, 0.7100118476630329]\n",
      "113 [0.7161833871316672, 0.7104360123125273]\n",
      "114 [0.7163423572037396, 0.7109157375294348]\n",
      "115 [0.7165287706383854, 0.7114508794550127]\n",
      "116 [0.7167422019477335, 0.7120410757440152]\n",
      "117 [0.7169379663187975, 0.71260734428758]\n",
      "118 [0.7171161904259757, 0.7131500439811024]\n",
      "119 [0.7172769930918326, 0.7136695211837685]\n",
      "120 [0.717420485306741, 0.7141661097378081]\n",
      "121 [0.7175467699096949, 0.7146401306424075]\n",
      "122 [0.7176559416283999, 0.7150918917746727]\n",
      "123 [0.7177480870080339, 0.7155216879434361]\n",
      "124 [0.7178232842375322, 0.7159298005541498]\n",
      "125 [0.7178816033092968, 0.7163164977583533]\n",
      "126 [0.7179231057114117, 0.7166820340152741]\n",
      "127 [0.7179478445722651, 0.7170266503115954]\n",
      "128 [0.7179558645044256, 0.7173505739114108]\n",
      "129 [0.7179472017236451, 0.7176540183765509]\n",
      "130 [0.7179218837965788, 0.7179371834787341]\n",
      "131 [0.7178799299643327, 0.7182002552533818]\n",
      "132 [0.7178213507478693, 0.7184434057886812]\n",
      "133 [0.7177461482506365, 0.7186667933307538]\n",
      "134 [0.7176543158867946, 0.7188705621990248]\n",
      "135 [0.7175458387251228, 0.7190548428573927]\n",
      "136 [0.7174206930878112, 0.7192197516795712]\n",
      "137 [0.7172788469380716, 0.7193653912371681]\n",
      "138 [0.7171202595982705, 0.7194918499304233]\n",
      "139 [0.7169448819485071, 0.7195992022572293]\n",
      "140 [0.7167526563040637, 0.7196875085786552]\n",
      "141 [0.7165435166337784, 0.7197568153076813]\n",
      "142 [0.7163173884120223, 0.7198071547111486]\n",
      "143 [0.7160741886694004, 0.719838544921761]\n",
      "144 [0.7158138261403951, 0.7198509899672718]\n",
      "145 [0.7155362011682957, 0.7198444796437322]\n",
      "146 [0.7152412058489482, 0.7198189896172956]\n",
      "147 [0.7149287239782096, 0.7197744812549233]\n",
      "148 [0.7145986312203528, 0.7197109016458871]\n",
      "149 [0.7142507951163947, 0.7196281836212571]\n",
      "150 [0.7138850751253508, 0.7195262456187212]\n",
      "151 [0.7135013226793574, 0.7194049916616632]\n",
      "152 [0.7130993813808274, 0.7192643113778883]\n",
      "153 [0.7126790869539676, 0.719104079863005]\n",
      "154 [0.712240267445151, 0.7189241577782621]\n",
      "155 [0.7117827432060475, 0.7187243911399018]\n",
      "156 [0.7113063272374974, 0.7185046115409301]\n",
      "157 [0.710810825051557, 0.7182646357909895]\n",
      "158 [0.7102960350037191, 0.7180042661873086]\n",
      "159 [0.7097782132906854, 0.7177531837576685]\n",
      "160 [0.7092408175560815, 0.7174814849540161]\n",
      "161 [0.7087002328061249, 0.7172190454885284]\n",
      "162 [0.7081397858850761, 0.7169357598803986]\n",
      "163 [0.7075759954147027, 0.7166617056284398]\n",
      "164 [0.7069920540836615, 0.7163665684659829]\n",
      "165 [0.7064046188340657, 0.7160806347285251]\n",
      "166 [0.7057967448294697, 0.7157733744743413]\n",
      "167 [0.7051852320853681, 0.715475289943271]\n",
      "168 [0.7045529951197693, 0.7151556287304713]\n",
      "169 [0.7039169817728206, 0.7148451160347435]\n",
      "170 [0.7032599629404848, 0.7145127702554095]\n",
      "171 [0.7025990388951144, 0.7141895465143856]\n",
      "172 [0.7019168340497289, 0.7138442273315899]\n",
      "173 [0.7012306057659982, 0.7135080047159211]\n",
      "174 [0.700522829505543, 0.7131494188221573]\n",
      "175 [0.6998109241104085, 0.7127999053439188]\n",
      "176 [0.6990772136895482, 0.712427755630537]\n",
      "177 [0.6983392830333591, 0.712064655886603]\n",
      "178 [0.6975793028163854, 0.7116786423097013]\n",
      "179 [0.6968150280424599, 0.7113016583211554]\n",
      "180 [0.6960472194776253, 0.7109225725904779]\n",
      "181 [0.6952759426344081, 0.7105413923510158]\n",
      "182 [0.6945012645021928, 0.710158125233668]\n",
      "183 [0.6937232533700554, 0.7097727792206449]\n",
      "184 [0.692941978847574, 0.7093853626693151]\n",
      "185 [0.6921575118642725, 0.7089958843570233]\n",
      "186 [0.6913699245461293, 0.7086043533079299]\n",
      "187 [0.6905792903341655, 0.708210779055073]\n",
      "188 [0.6897856838588229, 0.7078151714672783]\n",
      "189 [0.6889891809346232, 0.7074175407932727]\n",
      "190 [0.688189858529448, 0.7070178976622253]\n",
      "191 [0.6873877947577086, 0.7066162531287625]\n",
      "192 [0.6865830687476577, 0.7062126184949579]\n",
      "193 [0.685775760757058, 0.7058070055776167]\n",
      "194 [0.6849659520386587, 0.7053994265303197]\n"
     ]
    }
   ],
   "source": [
    "def feedForward(inputs):\n",
    "    \n",
    "    outputActivationValues = []\n",
    "    \n",
    "    # injecting inputs into input layer üíâ\n",
    "    input_layer[0].activationValue = inputs[0]\n",
    "    input_layer[1].activationValue = inputs[1]\n",
    "        \n",
    "    # activating the hidden layer\n",
    "    for i in range(len(hidden_layer)):\n",
    "        hidden_layer[i].activate(input_layer,(i-1))\n",
    "        \n",
    "    # feed forward\n",
    "    output_layer[0].activate(hidden_layer,0)\n",
    "    output_layer[1].activate(hidden_layer,1)\n",
    "    \n",
    "    # return activation values of output neurons\n",
    "    outputActivationValues = [output_layer[0].activationValue, output_layer[1].activationValue]\n",
    "#     outputActivationValues.append(output_layer[0].activationValue)\n",
    "#     outputActivationValues.append(output_layer[1].activationValue)\n",
    "    return outputActivationValues\n",
    "\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print(i, feedForward(inputs[i]))\n",
    "\n",
    "# Bad scaling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackPropagation(outputs):\n",
    "    \n",
    "    error = []\n",
    "    lamb = 5\n",
    "    lr = 2\n",
    "    momentum = 3\n",
    "    \n",
    "    # error = (output - expected) * transfer_derivative(output)\n",
    "    for i in range(len(output_layer)):\n",
    "        e = outputs[i] - output_layer[i].activationValue \n",
    "        error.append(e)\n",
    "        \n",
    "    for i in range(0,len(output_layer)):\n",
    "        output_layer[i].grad_val = lamb * output_layer[i].activationValue * (1 - output_layer[i].activationValue) * error[i]\n",
    "        \n",
    "    for k in range(0,len(hidden_layer)):\n",
    "        g = lamb * hidden_layer[k].activationValue * (1 - hidden_layer[k].activationValue)\n",
    "        result = 0\n",
    "        for i in range(0,len(output_layer)):\n",
    "            result = result + (output_layer[i].grad_val * hidden_layer[k].weights[i])\n",
    "        \n",
    "        hidden_layer[k].grad_val = g * result\n",
    "        \n",
    "    for z in range(0, len(hidden_layer)):\n",
    "        for y in range(0,len(output_layer)):\n",
    "            #error backprop: dw(delta weight) -->  back propped error \n",
    "            hidden_layer[z].dw[y] = lr * output_layer[y].grad_val * hidden_layer[y].activationValue + momentum * hidden_layer[z].dw[y]\n",
    "    \n",
    "    for y in range(0, len(i_layer)):\n",
    "        for a in range(0,len(hidden_layer)-1):\n",
    "            i_layer[y].dw[a] = lr * hidden_layer[a].grad_val * i_layer[a].activationValue + momentum * i_layer[y].dw[a]\n",
    "    \n",
    "    for x in range(0, len(hidden_layer)):\n",
    "        for i in range(0,len(output_layer)-1):\n",
    "            hidden_layer[y].weights[i] = hidden_layer[x].dw[i] * hidden_layer[x].weights[i]\n",
    "    # Why? input layer has no weights!\n",
    "    for y in range(0, len(i_layer)):\n",
    "        for a in range(0,len(hidden_layer)-1):\n",
    "            i_layer[y].weights[a] = i_layer[y].dw[a] * i_layer[y].weights[a]\n",
    "            \n",
    "for i in range(0, len(outputs)):\n",
    "    print(i, BackPropagation(outputs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb64d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086e19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
