{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba442ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f93cba",
   "metadata": {},
   "source": [
    "## Data Initialsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a84a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (distance)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# outputs (velocity)\n",
    "vx = []\n",
    "vy = []\n",
    "\n",
    "# parse the data into the set container\n",
    "with open('ce889_dataCollectionN.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    for line in csv_reader:\n",
    "        x.append(float(line[0]))\n",
    "        y.append(float(line[1]))\n",
    "        vx.append(float(line[2]))\n",
    "        vy.append(float(line[3]))\n",
    "\n",
    "inputs = list(zip(x,y))\n",
    "outputs = list(zip(vx,vy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e8cf5",
   "metadata": {},
   "source": [
    "## Neuron Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a493d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "        \n",
    "    def sigmoid(self,inputs):\n",
    "        sig = 1 / (1+math.exp(-inputs))\n",
    "        return sig\n",
    "    \n",
    "    def activate(self, prev_layer, index):\n",
    "        total = 0\n",
    "        for i in range(0, len(prev_layer)):\n",
    "            total = total + float(prev_layer[i].activationValue) * prev_layer[i].weights[index]\n",
    "            self.activationValue = self.sigmoid(total)\n",
    "#     def updateWeight\n",
    "            \n",
    "    def __init__ (self, activationValue, numberOfweights, layerIndex):\n",
    "        self.activationValue = activationValue\n",
    "        self.weights= [random() for i in range(numberOfweights + 1)]\n",
    "        self.delta_weight = [0,0]\n",
    "        self.grad_val = 0\n",
    "        self.layerIndex = layerIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "980989b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5704816216560269, 0.22209940245649107, 0.3645180870861692, 0.4697008147601516, 0.24509254499059085, 0.9274992891274992]\n"
     ]
    }
   ],
   "source": [
    "# Debugging ( just a cat passing by üêà)\n",
    "randCat = [random() for i in range(5+1)]\n",
    "print (randCat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fef9e",
   "metadata": {},
   "source": [
    "## Network Initialsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b627a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialsation of the network\n",
    "bias = -0.5\n",
    "n_hiddenNeurons = 3\n",
    "n_outNeurons = 2\n",
    "\n",
    "# Network\n",
    "# network = [neuron(0,n_hiddenNeurons,0),\n",
    "#            neuron(0,n_hiddenNeurons,0),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,n_outNeurons,1),\n",
    "#            neuron(0,0,2),\n",
    "#            neuron(0,0,2)\n",
    "#           ]\n",
    "\n",
    "input_layer = [neuron(0,n_hiddenNeurons,0),\n",
    "               neuron(0,n_hiddenNeurons,0)]\n",
    "\n",
    "hidden_layer = [neuron(0,n_outNeurons,1),\n",
    "                neuron(0,n_outNeurons,1),\n",
    "                neuron(0,n_outNeurons,1)]\n",
    "\n",
    "output_layer = [neuron(0,0,2),\n",
    "                neuron(0,0,2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a777adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual weight adjustment\n",
    "\n",
    "# input_layer[0].weights = [0.1,0.1,0.1,bias]\n",
    "# input_layer[1].weights = [0.1,0.1,0.1,bias]\n",
    "\n",
    "# Add Bias to the end of the weight list\n",
    "# hidden_layer[0].weights = [0.7,0.7,bias]\n",
    "# hidden_layer[1].weights = [0.5,0.5,bias]\n",
    "# hidden_layer[2].weights = [0.6,0.6,bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85b2d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.6431622329365528, 0.6617105175933778]\n",
      "1 [0.6431622329365528, 0.6617105175933778]\n",
      "2 [0.6431645578010107, 0.6617125840029816]\n",
      "3 [0.643176273278629, 0.6617196935803968]\n",
      "4 [0.6431903118870695, 0.6617288685915836]\n",
      "5 [0.6432137368608241, 0.6617430846457358]\n",
      "6 [0.6432394804459787, 0.6617593636502618]\n",
      "7 [0.643274602291643, 0.6617806797477448]\n",
      "8 [0.64331203551015, 0.6618040548446448]\n",
      "9 [0.6433588349002707, 0.6618324611873908]\n",
      "10 [0.6434079356316956, 0.6618629210701815]\n",
      "11 [0.6434663865243773, 0.6618984044962576]\n",
      "12 [0.6435271259103266, 0.6619359344782817]\n",
      "13 [0.643597195318824, 0.6619784783324146]\n",
      "14 [0.6436695374631772, 0.6620230601865262]\n",
      "15 [0.643751185410673, 0.6620726443057164]\n",
      "16 [0.6438350873492461, 0.6621242562545884]\n",
      "17 [0.6439282665797429, 0.6621808568082447]\n",
      "18 [0.644023678033484, 0.6622394733858187]\n",
      "19 [0.6441283338830288, 0.6623030628157008]\n",
      "20 [0.6442351969813034, 0.6623686547283736]\n",
      "21 [0.6443518715099776, 0.6624394554335229]\n",
      "22 [0.6444719167084204, 0.662512741293167]\n",
      "23 [0.6446028878228004, 0.6625916942867325]\n",
      "24 [0.6447383177937563, 0.662673573566041]\n",
      "25 [0.6448787277099074, 0.6627585856497662]\n",
      "26 [0.6450246178525418, 0.662846925881914]\n",
      "27 [0.6451764670721565, 0.6629387782410151]\n",
      "28 [0.6453347319962437, 0.6630343150698553]\n",
      "29 [0.6454998460978076, 0.6631336967430669]\n",
      "30 [0.6456722190793563, 0.6632370715335666]\n",
      "31 [0.6458522358576959, 0.6633445752525775]\n",
      "32 [0.6460402558994122, 0.6634563311226973]\n",
      "33 [0.6462366123389545, 0.6635724495256843]\n",
      "34 [0.646441611177282, 0.6636930278195022]\n",
      "35 [0.6466555305208634, 0.6638181501877459]\n",
      "36 [0.6468786196355192, 0.6639478873866675]\n",
      "37 [0.6471110983649658, 0.664082296729663]\n",
      "38 [0.6473531561501819, 0.6642214218388617]\n",
      "39 [0.6476049513676112, 0.6643652925942776]\n",
      "40 [0.647866610569774, 0.664513925030293]\n",
      "41 [0.6481382277769202, 0.6646673212803493]\n",
      "42 [0.6484198636735949, 0.6648254694583954]\n",
      "43 [0.6487115450234758, 0.664988343671761]\n",
      "44 [0.6490132640815128, 0.6651559040360205]\n",
      "45 [0.6493249778407066, 0.665328096591719]\n",
      "46 [0.649646607664814, 0.6655048534278423]\n",
      "47 [0.6499780386842596, 0.6656860926716247]\n",
      "48 [0.6503191194687816, 0.6658717186090658]\n",
      "49 [0.6506696616756744, 0.6660616217800025]\n",
      "50 [0.6510294724147212, 0.6662557530442653]\n",
      "51 [0.6513789173575627, 0.6664445586426541]\n",
      "52 [0.6517180991862982, 0.6666280748657379]\n",
      "53 [0.6520471208475078, 0.666806337868845]\n",
      "54 [0.6523660850948678, 0.6669793835013513]\n",
      "55 [0.6526750943825332, 0.6671472473308192]\n",
      "56 [0.6529742503795773, 0.6673099644438507]\n",
      "57 [0.6532636539629342, 0.6674675695161871]\n",
      "58 [0.6535434048400053, 0.6676200966634619]\n",
      "59 [0.6538136014403408, 0.6677675794472563]\n",
      "60 [0.6540743406762625, 0.6679100507895365]\n",
      "61 [0.6543257177656379, 0.668047542929385]\n",
      "62 [0.6545678260766749, 0.6681800873824301]\n",
      "63 [0.6548007569453403, 0.6683077148812488]\n",
      "64 [0.655024599632289, 0.6684304553929303]\n",
      "65 [0.655239441099508, 0.6685483380280761]\n",
      "66 [0.6554453659019802, 0.6686613910119634]\n",
      "67 [0.655642456143864, 0.6687696416955129]\n",
      "68 [0.6558307913336628, 0.6688731164935996]\n",
      "69 [0.656010448295399, 0.6689718408637862]\n",
      "70 [0.6561815010647727, 0.6690658392682299]\n",
      "71 [0.6563440209405941, 0.6691551352253848]\n",
      "72 [0.6564980761775111, 0.6692397511477461]\n",
      "73 [0.65664373222936, 0.6693197085071803]\n",
      "74 [0.656781051439293, 0.6693950276566988]\n",
      "75 [0.6569100931544365, 0.6694657279268861]\n",
      "76 [0.6570309135284079, 0.6695318275050843]\n",
      "77 [0.657143565706161, 0.6695933435703677]\n",
      "78 [0.6572480995361395, 0.6696502921216577]\n",
      "79 [0.6573445617547321, 0.6697026880988979]\n",
      "80 [0.657432995814317, 0.6697505452914383]\n",
      "81 [0.657513441928372, 0.669793876365799]\n",
      "82 [0.6575859370279326, 0.6698326928442111]\n",
      "83 [0.6576505147671569, 0.6698670051214156]\n",
      "84 [0.6577072054920109, 0.6698968224400381]\n",
      "85 [0.6577560361970809, 0.6699221528722321]\n",
      "86 [0.6577970305828332, 0.6699430033594446]\n",
      "87 [0.6578302090003045, 0.6699593796760196]\n",
      "88 [0.6578555884438151, 0.6699712864307853]\n",
      "89 [0.6578731825296139, 0.6699787270540237]\n",
      "90 [0.657883001574712, 0.669981703850629]\n",
      "91 [0.6578850524567044, 0.6699802179080154]\n",
      "92 [0.6578793387257543, 0.6699742691724444]\n",
      "93 [0.6578658606111519, 0.6699638564526401]\n",
      "94 [0.6578446148777204, 0.6699489773299251]\n",
      "95 [0.6578155950087206, 0.6699296282713328]\n",
      "96 [0.6577787910723542, 0.6699058045483524]\n",
      "97 [0.657734189823944, 0.6698775003006731]\n",
      "98 [0.6576874208290769, 0.6698473257501018]\n",
      "99 [0.6576328290212967, 0.6698126586759217]\n",
      "100 [0.6575760502494861, 0.6697761108242605]\n",
      "101 [0.657511417773027, 0.6697350559499716]\n",
      "102 [0.6574445753837828, 0.6696921077989505]\n",
      "103 [0.6573698429611757, 0.6696446355981313]\n",
      "104 [0.6572928740502056, 0.6695952556545349]\n",
      "105 [0.6572253243792253, 0.669550279926105]\n",
      "106 [0.6571672178922356, 0.6695097170810203]\n",
      "107 [0.6571185692285055, 0.6694735738842409]\n",
      "108 [0.657079383587681, 0.6694418551198986]\n",
      "109 [0.6570496568162776, 0.6694145636459387]\n",
      "110 [0.6570293309050173, 0.669391627688728]\n",
      "111 [0.6570183159624476, 0.6693729622411321]\n",
      "112 [0.6570164899501623, 0.6693584691176829]\n",
      "113 [0.6570236986001453, 0.6693480370940296]\n",
      "114 [0.657039755286331, 0.6693415419754688]\n",
      "115 [0.6570644410633855, 0.6693388467396673]\n",
      "116 [0.657097504880864, 0.6693398017359873]\n",
      "117 [0.6571224675676136, 0.6693361874964434]\n",
      "118 [0.6571393591612965, 0.669328005646665]\n",
      "119 [0.6571482064848273, 0.6693152567084651]\n",
      "120 [0.6571490331791985, 0.669297940120974]\n",
      "121 [0.6571418595573328, 0.6692760541536414]\n",
      "122 [0.6571267027160994, 0.6692495959908148]\n",
      "123 [0.6571035764937705, 0.6692185617003052]\n",
      "124 [0.6570724914341033, 0.6691829462202353]\n",
      "125 [0.6570334548950483, 0.6691427434256034]\n",
      "126 [0.6569864709342998, 0.6690979460658477]\n",
      "127 [0.6569315403909828, 0.66904854581055]\n",
      "128 [0.6568686608431831, 0.6689945332285128]\n",
      "129 [0.6567978267118767, 0.668935897855559]\n",
      "130 [0.6567190291115873, 0.6688726280957908]\n",
      "131 [0.656632256097767, 0.6688047113846631]\n",
      "132 [0.6565374924369106, 0.6687321340404773]\n",
      "133 [0.6564347198260024, 0.6686548814067721]\n",
      "134 [0.6563239167259689, 0.6685729377418554]\n",
      "135 [0.6562050586170113, 0.6684862863864803]\n",
      "136 [0.6560781177667869, 0.668394909614893]\n",
      "137 [0.6559430634705938, 0.668298788784298]\n",
      "138 [0.6557998619346499, 0.668197904268145]\n",
      "139 [0.6556484763790001, 0.6680922355137519]\n",
      "140 [0.6554888670085284, 0.6679817610295126]\n",
      "141 [0.6553209911453176, 0.6678664584648871]\n",
      "142 [0.6551448031715388, 0.667746304577049]\n",
      "143 [0.6549602545737724, 0.6676212752578062]\n",
      "144 [0.654767294053697, 0.6674913456041173]\n",
      "145 [0.6545658674923592, 0.6673564898957501]\n",
      "146 [0.6543559180410049, 0.6672166816490757]\n",
      "147 [0.6541373861234266, 0.6670718936211083]\n",
      "148 [0.6539102095590673, 0.6669220978869504]\n",
      "149 [0.6536743235687296, 0.666767265838019]\n",
      "150 [0.6534296608350287, 0.6666073682221344]\n",
      "151 [0.6531761515483929, 0.6664423751689988]\n",
      "152 [0.6529137235467759, 0.6662722562760532]\n",
      "153 [0.6526423023076163, 0.6660969806004654]\n",
      "154 [0.6523618110713142, 0.6659165167292966]\n",
      "155 [0.6520721708688048, 0.665730832796179]\n",
      "156 [0.6517733007207903, 0.6655398965950349]\n",
      "157 [0.6514651176053762, 0.6653436755600446]\n",
      "158 [0.6511475366362242, 0.6651421368607446]\n",
      "159 [0.6508263121902778, 0.6649379847969]\n",
      "160 [0.650495567635665, 0.6647284637363376]\n",
      "161 [0.6501611082288892, 0.6645162929439776]\n",
      "162 [0.6498170069436273, 0.6642987027753388]\n",
      "163 [0.6494691215675902, 0.6640784279222597]\n",
      "164 [0.6491114737905802, 0.6638526846932142]\n",
      "165 [0.6487499754935296, 0.6636242236200186]\n",
      "166 [0.6483785961865274, 0.6633902469098238]\n",
      "167 [0.6480033034091184, 0.663153521359475]\n",
      "168 [0.6476180137479634, 0.6629112350990232]\n",
      "169 [0.6472287519396733, 0.6626661716097638]\n",
      "170 [0.646829380988339, 0.6624155050022072]\n",
      "171 [0.6464259842540383, 0.6621620358044049]\n",
      "172 [0.6460123705640695, 0.661902924183604]\n",
      "173 [0.6455946833361609, 0.6616409880974302]\n",
      "174 [0.6451666768563024, 0.6613733739653663]\n",
      "175 [0.6447345558519081, 0.6611029174610161]\n",
      "176 [0.6442920197321949, 0.6608267514421852]\n",
      "177 [0.6438453358097374, 0.660547729618673]\n",
      "178 [0.6433881484774292, 0.6602629715688906]\n",
      "179 [0.642926788765244, 0.6599753492911228]\n",
      "180 [0.6424639003500311, 0.6596870480818536]\n",
      "181 [0.6419995186116277, 0.6593980880480438]\n",
      "182 [0.6415336795115527, 0.6591084895845005]\n",
      "183 [0.6410664194825609, 0.6588182733037493]\n",
      "184 [0.6405977754432856, 0.6585274600451928]\n",
      "185 [0.6401277847944356, 0.6582360708713123]\n",
      "186 [0.6396564853712212, 0.6579441270442995]\n",
      "187 [0.639183915482171, 0.657651650041274]\n",
      "188 [0.6387101138609308, 0.6573586615305896]\n",
      "189 [0.6382351196610279, 0.6570651833673418]\n",
      "190 [0.637758972441659, 0.656771237584847]\n",
      "191 [0.6372817121620662, 0.6564768463899081]\n",
      "192 [0.6368033791311404, 0.6561820321382884]\n",
      "193 [0.6363240140456109, 0.6558868173493329]\n",
      "194 [0.6358436579391511, 0.6555912246811998]\n"
     ]
    }
   ],
   "source": [
    "def feedForward(inputs):\n",
    "    \n",
    "    outputActivationValues = []\n",
    "    \n",
    "    # injecting inputs into input layer üíâ\n",
    "    input_layer[0].activationValue = inputs[0]\n",
    "    input_layer[1].activationValue = inputs[1]\n",
    "        \n",
    "    # activating the hidden layer\n",
    "    for i in range(len(hidden_layer)):\n",
    "        hidden_layer[i].activate(input_layer,(i-1))\n",
    "        \n",
    "    # feed forward\n",
    "    output_layer[0].activate(hidden_layer,0)\n",
    "    output_layer[1].activate(hidden_layer,1)\n",
    "    \n",
    "    # return activation values of output neurons\n",
    "    outputActivationValues = [output_layer[0].activationValue, output_layer[1].activationValue]\n",
    "#     outputActivationValues.append(output_layer[0].activationValue)\n",
    "#     outputActivationValues.append(output_layer[1].activationValue)\n",
    "    return outputActivationValues\n",
    "\n",
    "\n",
    "print(feedForward(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3aa2918",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'neuron' object has no attribute 'dw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ecae3b6d7679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-ecae3b6d7679>\u001b[0m in \u001b[0;36mBackPropagation\u001b[1;34m(outputs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#error backprop: dw(delta weight) -->  back propped error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mhidden_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_val\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivationValue\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'neuron' object has no attribute 'dw'"
     ]
    }
   ],
   "source": [
    "def BackPropagation(outputs):\n",
    "    \n",
    "    error = []\n",
    "    lamb = 5\n",
    "    lr = 2\n",
    "    momentum = 3\n",
    "    \n",
    "    # error = (output - expected) * transfer_derivative(output)\n",
    "    for i in range(len(output_layer)):\n",
    "        e = outputs[i] - output_layer[i].activationValue \n",
    "        error.append(e)\n",
    "        \n",
    "    for i in range(0,len(output_layer)):\n",
    "        output_layer[i].grad_val = lamb * output_layer[i].activationValue * (1 - output_layer[i].activationValue) * error[i]\n",
    "        \n",
    "    for k in range(0,len(hidden_layer)):\n",
    "        g = lamb * hidden_layer[k].activationValue * (1 - hidden_layer[k].activationValue)\n",
    "        result = 0\n",
    "        for i in range(0,len(output_layer)):\n",
    "            result = result + (output_layer[i].grad_val * hidden_layer[k].weights[i])\n",
    "        \n",
    "        hidden_layer[k].grad_val = g * result\n",
    "        \n",
    "    for z in range(0, len(hidden_layer)):\n",
    "        for y in range(0,len(output_layer)):\n",
    "            #error backprop: dw(delta weight) -->  back propped error \n",
    "            hidden_layer[z].dw[y] = lr * output_layer[y].grad_val * hidden_layer[y].activationValue + momentum * hidden_layer[z].dw[y]\n",
    "    \n",
    "    for y in range(0, len(i_layer)):\n",
    "        for a in range(0,len(hidden_layer)-1):\n",
    "            i_layer[y].dw[a] = lr * hidden_layer[a].grad_val * i_layer[a].activationValue + momentum * i_layer[y].dw[a]\n",
    "    \n",
    "    for x in range(0, len(hidden_layer)):\n",
    "        for i in range(0,len(output_layer)-1):\n",
    "            hidden_layer[y].weights[i] = hidden_layer[x].dw[i] * hidden_layer[x].weights[i]\n",
    "    # Why? input layer has no weights!\n",
    "    for y in range(0, len(i_layer)):\n",
    "        for a in range(0,len(hidden_layer)-1):\n",
    "            i_layer[y].weights[a] = i_layer[y].dw[a] * i_layer[y].weights[a]\n",
    "            \n",
    "for i in range(0, len(outputs)):\n",
    "    print(i, BackPropagation(outputs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb64d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086e19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
